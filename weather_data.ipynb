{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93affa6b-fe29-4b91-8d2f-6e0fc2e5742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando fila 1/9999...\n",
      "✓ Datos actualizados para fila 1\n",
      "Procesando fila 2/9999...\n",
      "✓ Datos actualizados para fila 2\n",
      "Procesando fila 3/9999...\n",
      "✓ Datos actualizados para fila 3\n",
      "Procesando fila 4/9999...\n",
      "✓ Datos actualizados para fila 4\n",
      "Procesando fila 5/9999...\n",
      "✓ Datos actualizados para fila 5\n",
      "Procesando fila 6/9999...\n",
      "✓ Datos actualizados para fila 6\n",
      "Procesando fila 7/9999...\n",
      "✓ Datos actualizados para fila 7\n",
      "Procesando fila 8/9999...\n",
      "✓ Datos actualizados para fila 8\n",
      "Procesando fila 9/9999...\n",
      "✓ Datos actualizados para fila 9\n",
      "Procesando fila 10/9999...\n",
      "✓ Datos actualizados para fila 10\n",
      "Procesando fila 11/9999...\n",
      "✓ Datos actualizados para fila 11\n",
      "Procesando fila 12/9999...\n",
      "✓ Datos actualizados para fila 12\n",
      "Procesando fila 13/9999...\n",
      "✓ Datos actualizados para fila 13\n",
      "Procesando fila 14/9999...\n",
      "✓ Datos actualizados para fila 14\n",
      "Procesando fila 15/9999...\n",
      "✓ Datos actualizados para fila 15\n",
      "Procesando fila 16/9999...\n",
      "✓ Datos actualizados para fila 16\n",
      "Procesando fila 17/9999...\n",
      "✓ Datos actualizados para fila 17\n",
      "Procesando fila 18/9999...\n",
      "✓ Datos actualizados para fila 18\n",
      "Procesando fila 19/9999...\n",
      "✓ Datos actualizados para fila 19\n",
      "Procesando fila 20/9999...\n",
      "✓ Datos actualizados para fila 20\n",
      "Procesando fila 21/9999...\n",
      "✓ Datos actualizados para fila 21\n",
      "Procesando fila 22/9999...\n",
      "✓ Datos actualizados para fila 22\n",
      "Procesando fila 23/9999...\n",
      "✓ Datos actualizados para fila 23\n",
      "Procesando fila 24/9999...\n",
      "✓ Datos actualizados para fila 24\n",
      "Procesando fila 25/9999...\n",
      "✓ Datos actualizados para fila 25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def obtener_datos_nasa(latitud, longitud, fecha):\n",
    "    \"\"\"\n",
    "    Obtiene datos climáticos de la NASA POWER API para una ubicación y fecha específicas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir fecha a formato YYYYMMDD\n",
    "        if isinstance(fecha, str):\n",
    "            fecha_obj = datetime.strptime(fecha, \"%Y-%m-%d\")\n",
    "        else:\n",
    "            fecha_obj = fecha\n",
    "        fecha_formateada = fecha_obj.strftime(\"%Y%m%d\")\n",
    "        \n",
    "        # Parámetros de la API\n",
    "        base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "        parametros = \"T2M,PRECTOTCORR,ALLSKY_SFC_SW_DWN,CLOUD_AMT\"\n",
    "        \n",
    "        # Construir URL\n",
    "        url = f\"{base_url}?parameters={parametros}&community=AG&longitude={longitud}&latitude={latitud}&start={fecha_formateada}&end={fecha_formateada}&format=JSON\"\n",
    "        \n",
    "        # Hacer solicitud a la API\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        datos = response.json()\n",
    "        \n",
    "        # Extraer los datos específicos\n",
    "        propiedades = datos['properties']['parameter']\n",
    "        geometria = datos['geometry']\n",
    "        \n",
    "        # Formatear los datos según especificaciones\n",
    "        temperatura = round(propiedades['T2M'][fecha_formateada], 1)\n",
    "        nubosidad = round(propiedades['CLOUD_AMT'][fecha_formateada], 1)\n",
    "        radiacion_solar = round(propiedades['ALLSKY_SFC_SW_DWN'][fecha_formateada], 2)\n",
    "        precipitacion = round(propiedades['PRECTOTCORR'][fecha_formateada], 1)\n",
    "        \n",
    "        return {\n",
    "            'temperatura_promedio': temperatura,\n",
    "            'nubosidad': nubosidad,\n",
    "            'radiacion_solar': f\"{radiacion_solar} MJ/m²\",\n",
    "            'precipitacion': f\"{precipitacion} mm\",\n",
    "            'geometria': json.dumps(geometria)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error obteniendo datos para lat {latitud}, lon {longitud}, fecha {fecha}: {e}\")\n",
    "        return None\n",
    "\n",
    "def procesar_ubicaciones():\n",
    "    \"\"\"\n",
    "    Procesa el CSV de ubicaciones y agrega los datos de NASA POWER\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Leer el CSV\n",
    "        df = pd.read_csv('ubicaciones.csv')\n",
    "        \n",
    "        # Verificar y agregar columnas si no existen\n",
    "        columnas_necesarias = ['temperatura_promedio', 'nubosidad', 'radiacion_solar', 'precipitacion', 'geometria']\n",
    "        for columna in columnas_necesarias:\n",
    "            if columna not in df.columns:\n",
    "                df[columna] = None\n",
    "        \n",
    "        # Procesar cada fila\n",
    "        for index, fila in df.iterrows():\n",
    "            # Saltar si ya tiene datos\n",
    "            if pd.notna(fila['temperatura_promedio']) and pd.notna(fila['nubosidad']):\n",
    "                continue\n",
    "            \n",
    "            print(f\"Procesando fila {index + 1}/{len(df)}...\")\n",
    "            \n",
    "            # Obtener datos de la fila actual\n",
    "            latitud = fila['latitud']\n",
    "            longitud = fila['longitud']\n",
    "            fecha = fila['fecha']\n",
    "            \n",
    "            # Obtener datos de NASA\n",
    "            datos_nasa = obtener_datos_nasa(latitud, longitud, fecha)\n",
    "            \n",
    "            if datos_nasa:\n",
    "                # Actualizar los datos en el DataFrame\n",
    "                for clave, valor in datos_nasa.items():\n",
    "                    df.at[index, clave] = valor\n",
    "                \n",
    "                # Guardar inmediatamente después de cada actualización\n",
    "                df.to_csv('ubicaciones.csv', index=False)\n",
    "                print(f\"✓ Datos actualizados para fila {index + 1}\")\n",
    "            else:\n",
    "                print(f\"✗ No se pudieron obtener datos para fila {index + 1}\")\n",
    "            \n",
    "            # Pequeña pausa para no saturar la API\n",
    "            time.sleep(1)\n",
    "            \n",
    "        print(\"Procesamiento completado!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en el procesamiento: {e}\")\n",
    "\n",
    "# Ejecutar el procesamiento\n",
    "if __name__ == \"__main__\":\n",
    "    procesar_ubicaciones()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
